{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 项目:travis data mining for tik tok vedio\n- **任务**：一般来说，为了吸引观众的注意力，广告视频的长度、音频、文本位置和画面会有与众不同之处。我们将通过对抖音平台上视频的时长、声音频谱、视频光谱、文字分布和画面变化等特征，构建一套商用广告视频识别系统来快速区分出投稿视频中的商用广告。\n- **步骤**：    \n                        1. 数据的探索与问题分析；\n                        2. 清洗数据；\n                            a.处理缺失值；\n                            b.标签转换；\n                            c.查看重复；\n                        3. 特征工程；\n                            a.特征选择；\n                            b.特征生成；\n                            c.特征分箱；\n                        4. 选择模型进行交叉验证和网格搜索；\n                        5. 模型的集成；\n                        6. 模型评价的深入思考；\n                        7. 进一步思考该项目。                     \n\n>**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"},{"metadata":{},"cell_type":"markdown","source":"---\n## 步骤一：数据的探索与问题分析\n\n阅读《基于机器学习的商用广告视频识别.pdf》文档，明确分析任务。\n阅读《数据集和变量说明.pdf》文档，简单了解数据，并描述数据基本特征。\n数据文件如下：\n- commercial_vedio_data.csv"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 导入依赖库\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#加载数据\ndata = pd.read_csv('commercial_vedio_data.csv',index_col=0)\ncol_name= data.columns[:-2]\nlabel_name = data.columns[-1]\n#查看数据的标签\nprint('训练集的标签：{}\\n'.format(label_name))\n#查看数据的特征\nprint('训练集的特征：{}\\n'.format(col_name))\n#查看数据的shape\nprint('训练集的形状：{}'.format(data.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 举个例子\n打印数据集的前5行数据"},{"metadata":{"trusted":false},"cell_type":"code","source":"# TODO：打印data的前五行数据","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 举个例子\n查看data数据集中标签('lables')的分布"},{"metadata":{"trusted":false},"cell_type":"code","source":"#data['labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# TODO：画出标签分布的直方图\n#frequency = dict()\n#for num in data['labels']:\n  #  frequency[num] = frequency.get(num, 0) + 1\n#plt.bar(list(frequency.keys()),\n        #list(frequency.values()))\n#plt.show()\n#以上是travis的示例\n#你自己写一个其他版本","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name '以上是travis的示例' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e7941bc882a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m#list(frequency.values()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m以上是travis的示例\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0m你自己写一个其他版本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name '以上是travis的示例' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"### 举个例子\n查看data数据集特征的的分布，对于describe善用转置可展示更多特征<br>\n真正了解你的数据，而非走形式"},{"metadata":{"trusted":false},"cell_type":"code","source":"# TODO：描述数据中特征的分布(表1)\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# TODO：描述数据\nfig=plt.figure(figsize=(6,6))\nax1=fig.add_subplot(1,1,1)\nax1.hist(data['1'],bins=2000,alpha=0.7)\nplt.title('times')\nplt.xlim([0,1000])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# TODO：描述数据中特征的分布(表3)\n#fig=plt.figure(figsize=(7,7))\n#ax1=fig.add_subplot(1,1,1)\n#ax1.hist(data['4124'],bins=2000,color='g',alpha=0.65)\n#plt.title('4124 feature')\n#plt.xlim([0,1])\n#plt.show()\n\n#以上是travis示例 自己写一个其他的对比 你的可能更好","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n## 步骤二：清洗数据\n\n在这一步中将开始清洗数据\n\n通过观察数据我们发现：\n\n- 数据需要查看是否存在缺失值；\n- 数据需要查看是否存在重复样本；\n- 虽然不同样本的相同特征取值变化不大，但特征间数值差距大；\n- 数据的标签需要变化。\n"},{"metadata":{},"cell_type":"markdown","source":"统计数据中的缺失值的数量\n- 统计数据集有多少行有缺失\n- 统计数据集有多少列有缺失"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 统计数据集中有多少行、列存在缺失\n#提示 用data.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 举个例子\n统计数据中的重复样本的数量\n- 统计数据集有多少行重复"},{"metadata":{"trusted":false},"cell_type":"code","source":"# TODO：统计数据集中有多少行重复","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 注意\n从上面我们可以看出数据的缺失值很多。结合文档中介绍的我们得到这些数据的方式，你觉得应如何处理缺失值？<br>\n\n\n下面给出一种思路。"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 将所有缺失值填补\n#data = data.fillna(data.mean())\n#也可以用0填充 数据很特殊","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 注意\n感觉特征间的尺度差距较大，注意在建模前结合模型要求进行适当的处理。"},{"metadata":{},"cell_type":"markdown","source":"### 标签数据转换\n将labels的值中的“-1”转换为0"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 将标签中的‘-1’转换为‘0’","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 分类特征重编码"},{"metadata":{},"cell_type":"markdown","source":"从上面的**数据探索**中的表中，可以看到有几个特征是无序的分类特征。因为无序特征各属性之间不能比较大小，通常情况下，要求无序特征（称为无序类别变量）被转换。无序转换类别变量的一种流行的方法是使用**独热编码**方案。独热编码为每一个无序分类特征的每一个可能的类别创建一个_“虚拟”_变量。例如，假设`someFeature`有三个可能的取值`A`，`B`或者`C`。我们将把这个特征编码成`someFeature_A`, `someFeature_B`和`someFeature_C`.\n\n| someFeature | someFeature_A | someFeature_B | someFeature_C |\n| :-: | :-: | :-: | :-: |\n|  A  | 1 | 0 | 0 |\n|  B  | 0 | 1 | 0 |\n|  C  | 0 | 0 | 1 |\n\n - 使用[`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies)对`'features_raw'`数据来施加一个独热编码。\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 是否需要对特征进行one-hot编码\n#要继续改\nindex = train_features_raw.shape[0]\ntemp = pd.get_dummies(pd.concat([train_features_raw,test_features_raw],axis=0))\ntrain = temp.iloc[:index]\ntest = temp.iloc[index:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 步骤三：特征工程\n\n- 特征过滤\n- 特征生成\n- 特征分箱\n\n可综合多种方法进行特征工程。一是使用某些方法生成新的特征纳入模型进行预测；\n二是通过某些方法进行特征过滤，减少纳入模型的特征数量；\n三是对连续特征进行特征分箱，离散特征进行特征组合。"},{"metadata":{},"cell_type":"markdown","source":"## 分离特征和标签"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 分离特征和标签\ntrain_label_raw = train['labels']\ntrain_features_raw = train.drop('labels', axis=1)\nprint(train_features_raw)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 划分训练集和测试集\n为避免测试集在特征工程步骤中被引入训练集信息，在进行特征工程前划分训练集和验证集。"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 将数据集划分为训练集和测试集\ntrains, tests = train_test_split(data, test_size=0.75)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 使用随机森林进行特征选择\n可用其他方法进行特征选择\n\n先来个示例:\n`'feature_importance_'` 属性的scikit学习分类器（例如随机森林）。         \n`'feature_importance_'` 属性是对特征的重要性排序的函数。\n在之后的步骤中将使用这个分类器拟合训练集数据并使用这个属性来对特征的重要程度进行排序。"},{"metadata":{"trusted":false},"cell_type":"code","source":"#使用随机森林进行特征选择，首先在训练集拟合随机森林模型\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#将特征的重要性程度进行排序\n#看了数据集就会清楚下,后面40多-110行之间有不少的缺失\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 保留训练集和测试集中对于分类最重要的前n个特征（自主考虑保留多少个特征?）\n# 以保留对于分类最重要的五十个特征为例，具体多少我也不知道哈哈\n#imp = np.argsort(rf.feature_importances_)[::-1]\n#imp_slct = imp[:50]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_slct=pd.DataFrame(X_train).iloc[:,imp_slct]\nX_test_slct=X_test.iloc[:,imp_slct]\n#请生成一个特征排序的热力图，读入特征排序后数组里的前五十个特征","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  使用 PCA进行特征生成\n\nPCA除了用于降维外，还可用于特征生成，即将选择出的主成分与原数据合并，一般会提升原数据的预测能力。"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 对训练集使用L1PCA生成新特征,首先查看各主成分解释方差比例\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#对训练集使用PCA生成新特征,根据累计贡献率，保留前5个主成分\npca1 = PCA(6)\npc = pd.DataFrame(pca1.fit_transform(X_train))\npc.index =  X_train.index\nX_train_pca = X_train.join(pc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# 对测试集进行相同的操作，注意测试集上直接使用pca中的transform函数\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  使用决策树进行特征分箱\n\n可以用所知道的其他方法进行此步\n\n特征分箱是常用的一种特征工程方法，它将连续变量离散化。合理的离散化将提升数据的预测能力。\n实现特征分箱的方法很多：\n- 简单地将数据等距分成n份\n- 简单地将数据等频分成n份\n- 根据卡方统计量优化分箱\n- 根据决策树优化分箱\n- 根据其他算法优化分箱\n\n一般还需根据WOE和IV评价分箱效果，在此不做进一步拓展了。\n以下代码是两函数是决策树优化分箱的示例(copy)\n- 注意:可以尝试将他们改装成类，实现更方便的调用?"},{"metadata":{"trusted":false},"cell_type":"code","source":"# 将训练集及其标签、测试集及其标签合并，以方便函数使用\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"'''\ncut_bin参数说明\n    df：训练集名称，如train\n    label：标签名称，如'labels'\n    max_depth：决策树最大深度\n    p：最小叶子节点数与样本量的比例\ncut_bin输出说明\n    df_bin：分箱后的数据集\n    dict_bin：储存分箱参数的字典，包含了用以评价分箱的WOE和IV\n'''\n'''\ncut_test_bin参数说明\n    df：测试集名称，如test\n    label：标签名称，如'labels'\n    train_dict_bin：训练集分箱生成的储存参数的字典\ncut_test_bin输出说明\n    df_bin：分箱后的数据集\n    dict_bin：储存分箱参数的字典，包含了用以评价分箱的WOE和IV\n    '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#  cut_bin对训练集进行分箱\n#  cut_test_bin对测试集进行分箱\ndef cut_bin(df,label,max_depth,p):\n    df_bin = df[[label]]\n    df_feature = df.drop([label],axis=1)\n    dict_bin = {}\n    for col in df_feature.columns:\n        get_model = DecisionTreeClassifier(max_depth=max_depth,min_samples_leaf=int(p*len(df)))\n        get_cut_point = get_model.fit(df[col].values.reshape(-1,1),df[label].values.reshape(-1,1))\n        cut_point = get_cut_point.tree_.threshold[get_cut_point.tree_.threshold!=-2]\n        \n        N_split = np.zeros_like(df[col])\n        inter_range = []\n        if len(cut_point)==1:\n            N_split[np.array(df[col]<cut_point[0])]=1\n            N_split[np.array(df[col]>=cut_point[0])]=2\n            inter_range=[[1,-100000000,cut_point[0]],[2,cut_point[0],100000000]]\n        elif len(cut_point)>1:\n            cut_point.sort()\n            N_split[np.array(df[col]<cut_point[0])]=1\n            inter_range=[[1,-100000000,cut_point[0]]]\n            for i in range(len(cut_point)-1):\n                N_split[np.array((df[col]>=cut_point[i]) & (df[col]<cut_point[i+1]))]=i+2\n                inter_range=inter_range+[[i+2,cut_point[i],cut_point[i+1]]]\n            N_split[np.array(df[col]>=cut_point[len(cut_point)-1])]=len(cut_point)+1\n            inter_range=inter_range+[[len(cut_point)+1,cut_point[len(cut_point)-1],100000000]]\n        else:\n            N_split=1\n            inter_range=np.array([1,-100000000,100000000]).reshape(1,-1)\n        df_bin[col] = N_split\n        inter_df = pd.DataFrame(inter_range)\n        inter_df.columns=['bin','lower','upper']\n        crosstable = pd.crosstab(df_bin[col],df_bin[label])\n        crosstable.columns = ['notCommercial','Commercial']\n        crosstable['all'] = crosstable['notCommercial']+crosstable['Commercial']\n        crosstable['percent'] = crosstable['all']/sum(crosstable['all'])\n        crosstable['c_rate'] = crosstable['Commercial']/crosstable['all']\n        inter_df = pd.merge(inter_df, crosstable, left_on='bin', right_index=True)\n        dict_bin[col] = inter_df\n    return df_bin, dict_bin\n\ndef cut_test_bin(df, label, train_dict_bin):\n    df_bin = df[[label]]\n    df_feature = df.drop([label],axis=1)\n    dict_bin = {}\n    for col in df_feature.columns:\n        train_bin = train_dict_bin[col]\n        splited = pd.Series([np.nan]*len(df[col]))\n        for i in range(len(train_bin['bin'])):\n            splited[((df[col]>=train_bin['lower'][i]) & (df[col]<train_bin['upper'][i])).tolist()]=train_bin['bin'][i]\n            df_bin[col]=splited.tolist()\n        crosstable = pd.crosstab(df_bin[col],df_bin[label])\n        crosstable.columns = ['notCommercial','Commercial']\n        crosstable['all'] = crosstable['notCommercial']+crosstable['Commercial']\n        crosstable['percent'] = crosstable['all']/sum(crosstable['all'])\n        crosstable['c_rate'] = crosstable['Commercial']/crosstable['all']\n        inter_df = pd.merge(train_bin[['bin','lower','upper']], crosstable, left_on='bin', right_index=True, how='left')\n        dict_bin[col] = inter_df\n    return df_bin, dict_bin   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n#调用函数完成特征分箱","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 分重新离特征和标签"},{"metadata":{"trusted":false},"cell_type":"code","source":"#再次分离特征和标签，训练集和测试集都要进行,之前我忘过\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 步骤四：选择模型进行交叉验证和网格搜索\n\n\n选择合适的模型以及评估方式，使用交叉验证和网格搜索建立模型，并选择合适的参数,打印出交叉验证的结果。\n- clf_model是分类模型。\n- 注意:模型对数据规整的需求。"},{"metadata":{},"cell_type":"markdown","source":"#模型选择、交叉验证、网格搜索\nclf_model = None\n\n# 这里演示最简单的模型更多的模型选择和参数调整\n\n# 对比使用随机森林和(xgboost/lightgbm二选一)\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(max_features=16,max_depth=12,n_estimators=2048,n_jobs=-1,random_state=0)\nrf.fit(X_train_bin,y_train)"},{"metadata":{},"cell_type":"markdown","source":"### 思考\n\n- 对于分类预测稳定性问题，使用accuracy、混淆矩阵和AUC指标来评估模型。\n\n- 注意： 除此以外，我觉得还可以设计一个随机猜测函数作为baseline来进一步查看模型相对于随机猜测是否有很大的优?\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n# 分类模型测试集上效果\n# auc和混淆矩阵评估\ny_train_pred_clf = rf.predict_proba(X_train_bin)\ny_train_pred = rf.predict(X_train_bin)\ny_test_pred_clf = rf.predict_proba(X_test_bin)\ny_test_pred = rf.predict(X_test_bin)\n# 评估训练集效果，直观判断是否过拟合\nprint('分类模型训练集表现：')\nprint('ml train model auc score {:.6f}'.format(roc_auc_score(y_train,y_train_pred_clf[:,1])))\nprint('---------------')\nprint('ml train model accuracy score {:.6f}'.format(accuracy_score(y_train,y_train_pred)))\nprint('---------------')\nthreshold = 0.5\nprint(confusion_matrix(y_train,(y_train_pred_clf>threshold)[:,1]))\n# 评估测试集效果\nprint('分类模型测试集表现：')\nprint('ml model auc score {:.6f}'.format(roc_auc_score(y_test,y_test_pred_clf[:,1])))\nprint('---------------')\nprint('ml model accuracy score {:.6f}'.format(accuracy_score(y_test,y_test_pred)))\nprint('---------------')\nthreshold = 0.5\nprint(confusion_matrix(y_test,(y_test_pred_clf>threshold)[:,1]))\n# 随机猜测函数对比\ny_test_random_clf = np.random.uniform(low=0.0,high=1.0,size=len(y_test))\n\nprint('random model auc score {:.6f}'.format(roc_auc_score(y_test,y_test_random_clf)))\nprint('---------------')\nprint(confusion_matrix(y_test,(y_test_random_clf<=threshold).astype('int')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 步骤五：模型集成\n尝试用stacking等方法对步骤四生成的不同学习器进行集成。\n\n注意评价集成后的模型。"},{"metadata":{"trusted":false},"cell_type":"code","source":"##模型集成举例\nensemble_model_clf = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 步骤六：模型评价和思考\n找到你认为最好的模型后，设定不同的分类阈值(threshold)仍会导致模型的实际应用效果有所不同，这无疑会影响模型的实际使用效果。ROC曲线是以模型在不同阈值下的真阳性率为纵轴，假阳性率为横轴绘制而成，它不仅可以不依靠阈值评价模型的预测效果。"},{"metadata":{"trusted":false},"cell_type":"code","source":"## 计算各阈值下假阳性率、真阳性率和AUC \nfrom sklearn.metrics import roc_curve, auc\nfpr,tpr,threshold = roc_curve(y_test,y_test_pred_clf[:,1])\nroc_auc = auc(fpr,tpr)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## 假阳性率为横坐标，真阳性率为纵坐标做曲线\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##生成一个混淆矩阵看看！","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"使用ACC和AUC评价模型，但是针对找出商用视频这一目的，是否有其他更合适的指标？结合混淆矩阵说明。"},{"metadata":{},"cell_type":"markdown","source":"## 创新点:\n也可以将整个流程调整为更合理的方式；\n\n尝试一下综合应用特征选择和特征生成，选择最适合本问题的方法；\n\n可以在特征选择，**之后**再生成新的特征。特征选择可以采取包裹法、过滤法或其他嵌入法进行。"},{"metadata":{"trusted":true},"cell_type":"code","source":"##特征选择+特征生成","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}